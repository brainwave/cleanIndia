{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports and setup\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import skimage as sk\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "from enum import Enum\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "#Loading the dataset from disk\n",
    "%matplotlib inline\n",
    "\n",
    "#Additional imports, to be moved to a new file later\n",
    "from sklearn import svm\n",
    "from scipy import sparse\n",
    "clf = svm.SVC(gamma=0.001, C=100.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(dirpath, img_width=64, img_height=64, channel_dim = 3, dtype=np.float32):\n",
    "\n",
    "    #Reading all files from all subdirectories \n",
    "    dict_class_label = {} #Map labels to values\n",
    "    \n",
    "    #POSSIBLE OPTIMIZATION - use imread_collection\n",
    "    num_files = sum([len(files) for _, dirs, files in os.walk(dirpath)])\n",
    "    num_items = 0\n",
    "    #num_files = num_dirs = 0\n",
    "    #for _, dirs, files in os.walk(dirpath):\n",
    "     #   num_files += len(files)\n",
    "      #  num_dirs  += 1\n",
    "\n",
    "    X = np.zeros((num_files, img_width, img_height, channel_dim), dtype = dtype) #64x64 thumbnails, preallocating space\n",
    "    y = np.zeros(num_files,dtype=np.uint8)\n",
    "\n",
    "    img_dirs = os.listdir(dirpath)\n",
    "\n",
    "    for label, img_dir in enumerate(img_dirs):\n",
    "        \n",
    "        dict_class_label[label] = img_dir\n",
    "        \n",
    "        img_files = os.listdir(os.path.join(dirpath, img_dir))    \n",
    "        #POSSIBLE OPTIMIZATION - Assign labels to y based on number of files\n",
    "        #Load all images into X\n",
    "        for i, img_file in enumerate(img_files):\n",
    "            img_file = os.path.join(dirpath, img_dir, img_file)\n",
    "            img = imread(img_file)\n",
    "            img = resize(img, (img_width,img_height),mode='constant')\n",
    "            X[num_items] = img\n",
    "            y[num_items] = label\n",
    "            num_items += 1\n",
    "            #Finished file load, data type is float at leaf level\n",
    "            \n",
    "            #subtract mean\n",
    "    return X, y, dict_class_label\n",
    "    \n",
    "# Load the dataset, perform sensibility checks\n",
    "X, y, labels = load_img('dataset-resized')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing - flatten image data\n",
    "def preprocess(X, y, normalize=False):\n",
    "    X = np.reshape(X, (X.shape[0],-1))\n",
    "    y = np.reshape(y, (y.shape[0], -1))\n",
    "\n",
    "    # Preprocessiong - subtract mean\n",
    "    if normalize is True:\n",
    "        X -= np.mean(X, axis = 0)\n",
    "\n",
    "    #Create sparse matrices out of data\n",
    "    X = sparse.csr_matrix(X)\n",
    "    y = y.ravel()\n",
    "    \n",
    "    return X, y\n",
    "#mean_img = np.mean(X, axis = 0)\n",
    "#plt.imshow(mean_img.reshape((64,64,3)).astype('uint8')) # visualize the mean image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = preprocess(X, y, normalize=True)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['svm.pkl']"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(clf, 'svm.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 2, 2], dtype=uint8)"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Prediction routine\n",
    "\n",
    "X, y, _ = load_img('dataset-test')\n",
    "X, _ = preprocess(X, y)\n",
    "\n",
    "clf.predict(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cleanIndia - Python 3.6.4",
   "language": "python",
   "name": "cleanindia"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
